#!/usr/bin/env python3
"""
Script Ä‘á»ƒ thÃªm dá»¯ liá»‡u tiáº¿ng Viá»‡t vÃ o Qdrant
Sá»­ dá»¥ng file luáº­t káº¿ toÃ¡n Viá»‡t Nam 2015 lÃ m dá»¯ liá»‡u máº«u
"""

import sys
import os
import json
import re
import asyncio
from typing import List, Dict, Any

# ThÃªm path Ä‘á»ƒ import modules
sys.path.append('src')

from qdrant_mcp.embedding.models.nomic import NomicEmbeddingModel
import requests


def read_vietnamese_law_file() -> str:
    """Äá»c file luáº­t káº¿ toÃ¡n Viá»‡t Nam"""
    file_path = "../../docs/luat_ke_toan_vietnam_2015.md"
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"âœ… ÄÃ£ Ä‘á»c file thÃ nh cÃ´ng: {len(content)} kÃ½ tá»±")
        return content
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c file: {e}")
        return ""


def split_content_into_chunks(content: str, max_length: int = 500) -> List[Dict[str, Any]]:
    """Chia ná»™i dung thÃ nh cÃ¡c chunk nhá»"""
    # Chia theo Ä‘oáº¡n vÄƒn
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    
    chunks = []
    for i, paragraph in enumerate(paragraphs):
        # Bá» qua cÃ¡c dÃ²ng quÃ¡ ngáº¯n
        if len(paragraph) < 50:
            continue
            
        # Chia Ä‘oáº¡n dÃ i thÃ nh cÃ¡c chunk nhá» hÆ¡n
        if len(paragraph) > max_length:
            sentences = re.split(r'[.!?]\s+', paragraph)
            current_chunk = ""
            
            for sentence in sentences:
                if len(current_chunk + sentence) > max_length and current_chunk:
                    chunks.append({
                        'id': len(chunks),
                        'text': current_chunk.strip(),
                        'metadata': {
                            'source': 'luat_ke_toan_vietnam_2015.md',
                            'chunk_type': 'paragraph_split',
                            'original_paragraph': i
                        }
                    })
                    current_chunk = sentence
                else:
                    current_chunk += " " + sentence if current_chunk else sentence
            
            if current_chunk.strip():
                chunks.append({
                    'id': len(chunks),
                    'text': current_chunk.strip(),
                    'metadata': {
                        'source': 'luat_ke_toan_vietnam_2015.md',
                        'chunk_type': 'paragraph_split',
                        'original_paragraph': i
                    }
                })
        else:
            chunks.append({
                'id': len(chunks),
                'text': paragraph,
                'metadata': {
                    'source': 'luat_ke_toan_vietnam_2015.md',
                    'chunk_type': 'full_paragraph',
                    'original_paragraph': i
                }
            })
    
    return chunks


def create_embeddings(chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Táº¡o embeddings cho cÃ¡c text chunks"""
    print("ğŸ”„ Äang táº¡o embeddings...")
    
    try:
        # Khá»Ÿi táº¡o Nomic embedding model
        model = NomicEmbeddingModel()
        
        embedded_chunks = []
        
        async def process_chunks():
            await model.load_model()
            
            for i, chunk in enumerate(chunks):
                print(f"Äang xá»­ lÃ½ chunk {i+1}/{len(chunks)}: {chunk['text'][:50]}...")
                
                # Táº¡o embedding
                embedding = await model.embed_text(chunk['text'], prompt_name="document")
                
                # ThÃªm embedding vÃ o chunk
                chunk['embedding'] = embedding
                embedded_chunks.append(chunk)
                
                # Giá»›i háº¡n sá»‘ lÆ°á»£ng Ä‘á»ƒ test
                if i >= 9:  # Chá»‰ xá»­ lÃ½ 10 chunks Ä‘áº§u
                    break
        
        # Cháº¡y async function
        asyncio.run(process_chunks())
        
        print(f"âœ… ÄÃ£ táº¡o embeddings cho {len(embedded_chunks)} chunks")
        return embedded_chunks
        
    except Exception as e:
        print(f"âŒ Lá»—i táº¡o embeddings: {e}")
        return []


def create_qdrant_collection(collection_name: str = "vietnamese_law") -> bool:
    """Táº¡o collection trong Qdrant"""
    url = "http://localhost:6333/collections/vietnamese_law"
    
    # XÃ³a collection cÅ© náº¿u cÃ³
    try:
        requests.delete(url)
        print("ğŸ—‘ï¸ ÄÃ£ xÃ³a collection cÅ©")
    except:
        pass
    
    # Táº¡o collection má»›i
    payload = {
        "vectors": {
            "size": 768,  # KÃ­ch thÆ°á»›c vector cá»§a Nomic
            "distance": "Cosine"
        }
    }
    
    try:
        response = requests.put(url, json=payload)
        if response.status_code in [200, 201]:
            print(f"âœ… ÄÃ£ táº¡o collection '{collection_name}' thÃ nh cÃ´ng")
            return True
        else:
            print(f"âŒ Lá»—i táº¡o collection: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Qdrant: {e}")
        return False


def upload_to_qdrant(embedded_chunks: List[Dict[str, Any]], collection_name: str = "vietnamese_law") -> bool:
    """Upload embeddings lÃªn Qdrant"""
    if not embedded_chunks:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ upload")
        return False
    
    url = f"http://localhost:6333/collections/{collection_name}/points"
    
    # Chuáº©n bá»‹ dá»¯ liá»‡u theo format cá»§a Qdrant
    points = []
    for chunk in embedded_chunks:
        points.append({
            "id": chunk['id'],
            "vector": chunk['embedding'],
            "payload": {
                "text": chunk['text'],
                "metadata": chunk['metadata']
            }
        })
    
    payload = {"points": points}
    
    try:
        print(f"ğŸš€ Äang upload {len(points)} Ä‘iá»ƒm dá»¯ liá»‡u...")
        response = requests.put(url, json=payload)
        
        if response.status_code in [200, 201]:
            print(f"âœ… ÄÃ£ upload thÃ nh cÃ´ng {len(points)} Ä‘iá»ƒm dá»¯ liá»‡u")
            return True
        else:
            print(f"âŒ Lá»—i upload: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Qdrant: {e}")
        return False


def test_search(query: str = "káº¿ toÃ¡n trÆ°á»Ÿng", collection_name: str = "vietnamese_law") -> None:
    """Test tÃ¬m kiáº¿m semantic"""
    print(f"\nğŸ” Test tÃ¬m kiáº¿m vá»›i query: '{query}'")
    
    try:
        # Táº¡o embedding cho query
        model = NomicEmbeddingModel()
        
        async def get_query_embedding():
            await model.load_model()
            return await model.embed_text(query, prompt_name="query")
        
        query_embedding = asyncio.run(get_query_embedding())
        
        # TÃ¬m kiáº¿m trong Qdrant
        url = f"http://localhost:6333/collections/{collection_name}/points/search"
        payload = {
            "vector": query_embedding,
            "limit": 3,
            "with_payload": True
        }
        
        response = requests.post(url, json=payload)
        
        if response.status_code == 200:
            results = response.json()
            print(f"âœ… TÃ¬m tháº¥y {len(results['result'])} káº¿t quáº£:")
            
            for i, result in enumerate(results['result']):
                score = result['score']
                text = result['payload']['text'][:200]
                print(f"\n{i+1}. Score: {score:.4f}")
                print(f"   Text: {text}...")
        else:
            print(f"âŒ Lá»—i tÃ¬m kiáº¿m: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"âŒ Lá»—i test tÃ¬m kiáº¿m: {e}")


def main():
    """HÃ m chÃ­nh"""
    print("ğŸš€ Báº¯t Ä‘áº§u thÃªm dá»¯ liá»‡u tiáº¿ng Viá»‡t vÃ o Qdrant")
    print("=" * 50)
    
    # 1. Äá»c file
    content = read_vietnamese_law_file()
    if not content:
        return
    
    # 2. Chia nhá» content
    print("\nğŸ“ Chia nhá» ná»™i dung...")
    chunks = split_content_into_chunks(content)
    print(f"âœ… ÄÃ£ chia thÃ nh {len(chunks)} chunks")
    
    # 3. Táº¡o embeddings
    print("\nğŸ§  Táº¡o embeddings...")
    embedded_chunks = create_embeddings(chunks)
    if not embedded_chunks:
        return
    
    # 4. Táº¡o collection
    print("\nğŸ—ƒï¸ Táº¡o Qdrant collection...")
    if not create_qdrant_collection():
        return
    
    # 5. Upload dá»¯ liá»‡u
    print("\nâ¬†ï¸ Upload dá»¯ liá»‡u...")
    if not upload_to_qdrant(embedded_chunks):
        return
    
    # 6. Test tÃ¬m kiáº¿m
    print("\nğŸ” Test tÃ¬m kiáº¿m...")
    test_search("káº¿ toÃ¡n trÆ°á»Ÿng")
    test_search("bÃ¡o cÃ¡o tÃ i chÃ­nh")
    test_search("Ä‘iá»u kiá»‡n kinh doanh")
    
    print("\nğŸ‰ HoÃ n thÃ nh!")


if __name__ == "__main__":
    main()
